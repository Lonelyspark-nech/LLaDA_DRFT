{
  
  "model_name_or_path": "/root/autodl-tmp/hf_cache/hub/models--GSAI-ML--LLaDA-8B-Base/snapshots/ce71e3c2523f535e022bccedbda192eb8869fd44",
  "peft_model_name_or_path": null,
  
  "dataset_name": "E5",
  "dataset_file_path": "cache/echo-data-50k",
  "disable_tqdm": false,
  "remove_unused_columns": false,

  "bidirectional": false,
  "loss_class":"MRL",
  "pooling_mode": "eos_token",

  "do_train": true,
  "learning_rate": 1e-4,
  "num_train_epochs": 2,
  "warmup_steps": 1250,
  "per_device_train_batch_size": 2,
  "per_device_eval_batch_size": 2,
  "gradient_accumulation_steps": 2,
  "lora_r": 16,
  "gradient_checkpointing": false,
  "torch_dtype": "bfloat16",
  "attn_implementation": "flash_attention_2",
  "seed": 42,
  "max_seq_length": 512,
  "logging_steps": 100,
  "save_steps": 100,
  "eval_steps": 100,
  "stop_after_n_steps": 100000,
  "do_eval": true,                           
 
  
  "save_only_model": true,
  "overwrite_output_dir": true,
  "output_dir": "/root/autodl-tmp/llm2vec-main/output/mntp-supervised/LLaDA",
                    
  "dataloader_num_workers": 16
}
